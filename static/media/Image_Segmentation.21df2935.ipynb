{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yk11eF3lmDgT"
   },
   "source": [
    "# **Image Classification**\n",
    "\n",
    "### **Image Classification** is a fundamental task that attempts to comprehend an entire image as a whole. The goal is to classify the image by assigning it to a specific label. Typically, Image Classification refers to images in which only one object appears and is analyzed. In contrast, object detection involves both classification and localization tasks, and is used to analyze more realistic cases in which multiple objects may exist in an image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF5r_x45sYst"
   },
   "source": [
    "## Machine Learning Algorithms\n",
    "\n",
    "## 1. K-Nearest Neighbors\n",
    "\n",
    "K-Nearest Neighbors is a classification algorithm that examines the closest training examples and looks at their labels to ascertain the most probable label for a given test example. When it comes to image classification using KNN, the feature vectors and labels of the training images are stored and just the feature vector is passed into the algorithm during testing.\n",
    "\n",
    "\n",
    "##2. Support Vector Machines\n",
    "\n",
    "Support Vector Machines are a classification method that places points in space and then draws dividing lines between the points, placing objects in different classes depending on which side of the dividing plane the points fall on. Support Vector Machines are capable of doing nonlinear classification through the use of a technique known as the kernel trick.\n",
    "\n",
    "##3. Deep Learning Algorithms (CNNs)\n",
    "<img src = \"https://ml8ygptwlcsq.i.optimole.com/fMKjlhs-QzMakt0P/w:740/h:228/q:auto/https://www.unite.ai/wp-content/uploads/2020/09/Typical_cnn.png\">\n",
    "\n",
    "The most commonly used image classification algorithm in recent times is the Convolutional Neural Network (CNNs). CNNs are customized versions of neural networks that combine the multilayer neural networks with specialized layers that are capable of extracting the features most important and relevant to the classification of an object. CNNs can automatically discover, generate, and learn features of images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPSEkmzC3LkC"
   },
   "source": [
    "## Introducing Convolutional Neural Networks\n",
    "\n",
    "## 1. Convolution\n",
    "A convolution extracts tiles of the input feature map, and applies filters to them to compute new features, producing an output feature map, or convolved feature (which may have a different size and depth than the input feature map). Convolutions are defined by two parameters:\n",
    "\n",
    "Size of the tiles that are extracted (typically 3x3 or 5x5 pixels).\n",
    "The depth of the output feature map, which corresponds to the number of filters that are applied.\n",
    "\n",
    "<img src =\"https://developers.google.com/machine-learning/practica/image-classification/images/convolution_overview.gif\">\n",
    "\n",
    "For each filter-tile pair, the CNN performs element-wise multiplication of the filter matrix and the tile matrix, and then sums all the elements of the resulting matrix to get a single value. Each of these resulting values for every filter-tile pair is then output in the convolved feature matrix\n",
    "\n",
    "<img src = \"https://developers.google.com/machine-learning/practica/image-classification/images/convolution_example.svg\">\n",
    "\n",
    "During training, the CNN \"learns\" the optimal values for the filter matrices that enable it to extract meaningful features (textures, edges, shapes) from the input feature map. As the number of filters (output feature map depth) applied to the input increases, so does the number of features the CNN can extract. \n",
    "\n",
    "\n",
    "## 2. Relu\n",
    "\n",
    "Following each convolution operation, the CNN applies a Rectified Linear Unit (ReLU) transformation to the convolved feature, in order to introduce nonlinearity into the model. The ReLU function,F(x) = max(0,x) , returns x for all values of x > 0, and returns 0 for all values of x â‰¤ 0.\n",
    "<img src = \"\">\n",
    "\n",
    "\n",
    "## 3. Max Pooling\n",
    "\n",
    "After ReLU comes a pooling step, in which the CNN downsamples the convolved feature (to save on processing time), reducing the number of dimensions of the feature map, while still preserving the most critical feature information. A common algorithm used for this process is called max pooling.\n",
    "\n",
    "Max pooling operations take two parameters:\n",
    "\n",
    "- Size of the max-pooling filter (typically 2x2 pixels)\n",
    "- Stride: the distance, in pixels, separating each extracted tile. Unlike with convolution, where filters slide over the feature map pixel by pixel, in max pooling, the stride determines the locations where each tile is extracted.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\">\n",
    "\n",
    "\n",
    "## 4. Fully Connected Layers\n",
    "At the end of a convolutional neural network are one or more fully connected layers (when two layers are \"fully connected,\" every node in the first layer is connected to every node in the second layer). Their job is to perform classification based on the features extracted by the convolutions. \n",
    "\n",
    "<img src =\"https://developers.google.com/machine-learning/practica/image-classification/images/cnn_architecture.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdndgEP_lFYC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XcJd_ZZlFYO"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 30 02:12:29 2019\n",
    "\n",
    "@author: Mithilesh\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" 1- Imported cv2 to read the image and also to convert the image from BGR to RGB.\n",
    "    2- Numpy is imported in order to do mathematical stuffs.\n",
    "    3- Matplotlib.pyplot is imported to draw the image .\n",
    "    4- KMeans is imported to perform KMeans-Clusterring. \"\"\"\n",
    "    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class Segmentation:\n",
    "    \n",
    "    def __init__(self,image,dom_colors):\n",
    "        #since cv2 reads image in BGR mode , it is necessary to convert into RGB mode.\n",
    "        self.image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        self.orginal_size=image.shape\n",
    "        #flatenning the image in order to make it compatible for KMeans class\n",
    "        self.pixel_array=self.image.reshape((-1,3))\n",
    "        self.dom_colors=dom_colors\n",
    "        #Created an instance of KMeans \n",
    "        self.km=KMeans(n_clusters=self.dom_colors)\n",
    "        #created a model here\n",
    "        self.km.fit(self.pixel_array)\n",
    "           \n",
    "    #this program helps to extract out the dominant colors from the image    \n",
    "    def dominant_colors(self):\n",
    "        #taking out the centers\n",
    "        self.centers=np.array(self.km.cluster_centers_,dtype='uint8')\n",
    "        self.colors=[]\n",
    "        plt.figure(0,(16,2))\n",
    "        var=1\n",
    "        for current_center in self.centers:\n",
    "            plt.subplot(1,self.dom_colors+1,var)\n",
    "            plt.gca().set_title(\"Color \"+str(var),fontsize=10)\n",
    "            plt.axis(\"off\")\n",
    "            self.colors.append(current_center)\n",
    "            #created an array to store data of each dominant color\n",
    "            color_array=np.zeros((100,100,3),dtype='uint8')\n",
    "            color_array[:,:,:]=current_center\n",
    "            plt.imshow(color_array)\n",
    "            var+=1\n",
    "        plt.show()\n",
    "        \n",
    "    #this fucntion draws the image with the given dominant colors\n",
    "    def draw_image(self):\n",
    "        self.centers=np.array(self.km.cluster_centers_,dtype='uint8')\n",
    "        #here predict function gives label to each point , i.e the given point is nearer to which center\n",
    "        pred=self.km.predict(self.pixel_array)\n",
    "        #creaed an empty array to store data of image \n",
    "        new_image=np.zeros((self.image.shape[0]*self.image.shape[1],3),dtype='uint8')\n",
    "        for i in range(new_image.shape[0]):\n",
    "            new_image[i]=self.centers[pred[i]]\n",
    "        #new_image is reshaped into original size in order to get whole image together\n",
    "        new_image=new_image.reshape(self.orginal_size)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"No. of colors : \"+str(self.dom_colors))\n",
    "        plt.imshow(new_image)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kmix7cTUlFYa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjrLtrWUlFYe",
    "outputId": "7b651cc0-4cbb-4024-9a66-2f7f8cdb167b"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a52b06ca1771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acutal Image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"default\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ7UlEQVR4nO3df5BdZX3H8feHxIAKim1iR5MotAYlZaroDmJtFUeqgbZJO+PQpGVASomjRTtqtVgdtDjTqb/q1CkdjJZatYrBzmhqo3FqsVprHJZSkMDQCRFhBSX8kGqpQPDbP+6Ne9ls2MPu3b1xn/drZifnx3PP+e4z937u2ef8SKoKSdLid9ioC5AkLQwDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+mpfklCQTo65Dmm8GvkYuyZeT3JPk8CFt7x1JPj6MbfW3V0meMaztSaNi4GukkhwD/CpQwPqRFiMtcga+Ru0sYCfwEeDswRVJHpvkfUm+neTeJP/eX3bAEEySm5OcmmQd8KfA7yT5YZJr+uvPSXJDkh8k2ZPkVbMptv/Xw+VJPt7f1jeTHJfkLUnuSHJrkpcNtH/E/SZ5c5Lbk9yW5A8G/5pIcniS9ya5Jcn3klyS5LGzqVsCA1+jdxbwD/2flyf5uYF17wWeB/wy8DPAm4EfP9LGquoLwJ8Dn6qqI6vq2f1VdwC/ATwBOAd4f5LnzrLm3wQ+BjwJuBrYQe+ztBK4CPjgQNuD7rf/5fQG4FTgGcCLp+znXcBxwHP661cCF86yZsnA1+gk+RXg6cDWqroKuAn43f66w4DfB/6oqr5TVQ9V1X9U1f2z2VdV/XNV3VQ9/wZ8kd5Q0mx8tap2VNU+4HJgBfAXVfUgcBlwTJKjO+z3DODvqmpXVd0H/Nn+HSQJcB7w+qq6u6p+QO+LbOMsa5YMfI3U2cAXq+rO/vwnmBzWWQ4cQe9LYM6SnJZkZ5K7k3wfOL2/j9n43sD0/wF3VtVDA/MAR3bY71OBWwe2NTi9AngccFWS7/df+4X+cmlWlo66ALWpPxZ9BrAkyXf7iw8Hjk7ybOCbwI+AXwCumfLy/6UXhvu3tYSHB+HDHgHbv/rnH+kNH322qh5M8hkgw/uNDtRhv7cDqwZesnpg+k56Xx6/WFXfmc861Q6P8DUqvwU8BKylN0b9HOB44KvAWVX1Y+BS4C+TPDXJkiQv6IfofwNHJPn1JI8B3kbvy2K/79EbVtn//l7WX78X2JfkNOBlzL+Z9rsVOCfJ8Ukex8D4fP/3/xC9Mf8nAyRZmeTlC1C3FikDX6NyNr3x61uq6rv7f4C/Bn4vyVLgj+kd6V8J3E3vJOZhVXUv8Brgw8B36B3xD161c3n/37uS/Gd//Pt19AL2HnrnCbbN9y84036r6vPAB4ArgN3A1/ur9p+n+JP+8p1J/gf4F+CZ8123Fq/4H6BIh4YkxwPXAYf3TwhLQ+URvjRCSX47ybIkT6L3F8w/GfaaLzMGfpJL+zeUXHeQ9UnygSS7k1w7h2ubpRa9it4Y/030zmm8erTlaDGbcUgnyYuAHwIfraoTpll/OvBaepebPR/4q6p6/jzUKkmagxmP8KvqK/ROmB3MBnpfBlVVO+ldVveUYRUoSRqOYVyHv5KH3zAy0V92+9SGSTYDmwEe//jHP+9Zz3rWEHYvSe246qqr7qyqWd2AN4zAn+7mlWnHiapqC7AFYGxsrMbHx4ewe0lqR5Jvz/a1w7hKZ4KH3yG4CrhtCNuVJA3RMAJ/G3BW/2qdk4F7q+qA4RxJ0mjNOKST5JPAKcDy/jPI3w48BqCqLgG207tCZzdwH71HwEqSDjEzBn5VbZphfQF/OLSKJEnzwjttJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRnQK/CTrktyYZHeSC6ZZ/7QkVyS5Osm1SU4ffqmSpLmYMfCTLAEuBk4D1gKbkqyd0uxtwNaqOhHYCPzNsAuVJM1NlyP8k4DdVbWnqh4ALgM2TGlTwBP6008EbhteiZKkYegS+CuBWwfmJ/rLBr0DODPJBLAdeO10G0qyOcl4kvG9e/fOolxJ0mx1CfxMs6ymzG8CPlJVq4DTgY8lOWDbVbWlqsaqamzFihWPvlpJ0qx1CfwJYPXA/CoOHLI5F9gKUFVfB44Alg+jQEnScHQJ/CuBNUmOTbKM3knZbVPa3AK8FCDJ8fQC3zEbSTqEzBj4VbUPOB/YAdxA72qcXUkuSrK+3+yNwHlJrgE+CbyyqqYO+0iSRmhpl0ZVtZ3eydjBZRcOTF8PvHC4pUmShsk7bSWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1olPgJ1mX5MYku5NccJA2ZyS5PsmuJJ8YbpmSpLlaOlODJEuAi4FfAyaAK5Nsq6rrB9qsAd4CvLCq7kny5PkqWJI0O12O8E8CdlfVnqp6ALgM2DClzXnAxVV1D0BV3THcMiVJc9Ul8FcCtw7MT/SXDToOOC7J15LsTLJuug0l2ZxkPMn43r17Z1exJGlWugR+pllWU+aXAmuAU4BNwIeTHH3Ai6q2VNVYVY2tWLHi0dYqSZqDLoE/AawemF8F3DZNm89W1YNV9S3gRnpfAJKkQ0SXwL8SWJPk2CTLgI3AtiltPgO8BCDJcnpDPHuGWagkaW5mDPyq2gecD+wAbgC2VtWuJBclWd9vtgO4K8n1wBXAm6rqrvkqWpL06KVq6nD8whgbG6vx8fGR7FuSfloluaqqxmbzWu+0laRGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGtEp8JOsS3Jjkt1JLniEdq9IUknGhleiJGkYZgz8JEuAi4HTgLXApiRrp2l3FPA64BvDLlKSNHddjvBPAnZX1Z6qegC4DNgwTbt3Au8GfjTE+iRJQ9Il8FcCtw7MT/SX/USSE4HVVfW5R9pQks1JxpOM792791EXK0mavS6Bn2mW1U9WJocB7wfeONOGqmpLVY1V1diKFSu6VylJmrMugT8BrB6YXwXcNjB/FHAC8OUkNwMnA9s8cStJh5YugX8lsCbJsUmWARuBbftXVtW9VbW8qo6pqmOAncD6qhqfl4olSbMyY+BX1T7gfGAHcAOwtap2Jbkoyfr5LlCSNBxLuzSqqu3A9inLLjxI21PmXpYkadi801aSGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIzoFfpJ1SW5MsjvJBdOsf0OS65Ncm+RLSZ4+/FIlSXMxY+AnWQJcDJwGrAU2JVk7pdnVwFhV/RLwaeDdwy5UkjQ3XY7wTwJ2V9WeqnoAuAzYMNigqq6oqvv6szuBVcMtU5I0V10CfyVw68D8RH/ZwZwLfH66FUk2JxlPMr53797uVUqS5qxL4GeaZTVtw+RMYAx4z3Trq2pLVY1V1diKFSu6VylJmrOlHdpMAKsH5lcBt01tlORU4K3Ai6vq/uGUJ0kali5H+FcCa5Icm2QZsBHYNtggyYnAB4H1VXXH8MuUJM3VjIFfVfuA84EdwA3A1qraleSiJOv7zd4DHAlcnuS/kmw7yOYkSSPSZUiHqtoObJ+y7MKB6VOHXJckaci801aSGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWpEp8BPsi7JjUl2J7lgmvWHJ/lUf/03khwz7EIlSXMzY+AnWQJcDJwGrAU2JVk7pdm5wD1V9Qzg/cC7hl2oJGluuhzhnwTsrqo9VfUAcBmwYUqbDcDf96c/Dbw0SYZXpiRprpZ2aLMSuHVgfgJ4/sHaVNW+JPcCPwvcOdgoyWZgc3/2/iTXzaboRWg5U/qqYfbFJPtikn0x6ZmzfWGXwJ/uSL1m0Yaq2gJsAUgyXlVjHfa/6NkXk+yLSfbFJPtiUpLx2b62y5DOBLB6YH4VcNvB2iRZCjwRuHu2RUmShq9L4F8JrElybJJlwEZg25Q224Cz+9OvAP61qg44wpckjc6MQzr9MfnzgR3AEuDSqtqV5CJgvKq2AX8LfCzJbnpH9hs77HvLHOpebOyLSfbFJPtikn0xadZ9EQ/EJakN3mkrSY0w8CWpEfMe+D6WYVKHvnhDkuuTXJvkS0mePoo6F8JMfTHQ7hVJKsmivSSvS18kOaP/3tiV5BMLXeNC6fAZeVqSK5Jc3f+cnD6KOudbkkuT3HGwe5XS84F+P12b5LmdNlxV8/ZD7yTvTcDPA8uAa4C1U9q8BrikP70R+NR81jSqn4598RLgcf3pV7fcF/12RwFfAXYCY6Oue4TvizXA1cCT+vNPHnXdI+yLLcCr+9NrgZtHXfc89cWLgOcC1x1k/enA5+ndA3Uy8I0u253vI3wfyzBpxr6oqiuq6r7+7E569zwsRl3eFwDvBN4N/Gghi1tgXfriPODiqroHoKruWOAaF0qXvijgCf3pJ3LgPUGLQlV9hUe+l2kD8NHq2QkcneQpM213vgN/uscyrDxYm6raB+x/LMNi06UvBp1L7xt8MZqxL5KcCKyuqs8tZGEj0OV9cRxwXJKvJdmZZN2CVbewuvTFO4Azk0wA24HXLkxph5xHmydAt0crzMXQHsuwCHT+PZOcCYwBL57XikbnEfsiyWH0nrr6yoUqaIS6vC+W0hvWOYXeX31fTXJCVX1/nmtbaF36YhPwkap6X5IX0Lv/54Sq+vH8l3dImVVuzvcRvo9lmNSlL0hyKvBWYH1V3b9AtS20mfriKOAE4MtJbqY3RrltkZ647foZ+WxVPVhV3wJupPcFsNh06Ytzga0AVfV14Ah6D1ZrTac8mWq+A9/HMkyasS/6wxgfpBf2i3WcFmboi6q6t6qWV9UxVXUMvfMZ66tq1g+NOoR1+Yx8ht4JfZIspzfEs2dBq1wYXfriFuClAEmOpxf4exe0ykPDNuCs/tU6JwP3VtXtM71oXod0av4ey/BTp2NfvAc4Eri8f976lqpaP7Ki50nHvmhCx77YAbwsyfXAQ8Cbququ0VU9Pzr2xRuBDyV5Pb0hjFcuxgPEJJ+kN4S3vH++4u3AYwCq6hJ65y9OB3YD9wHndNruIuwrSdI0vNNWkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RG/D/9MqYKokm9ywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=cv2.imread(\"D:\\C\\Sherlock.jpg\")\n",
    "plt.title(\"Acutal Image\")\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "for i in range(2,11,4):\n",
    "    IS=Segmentation(img,i)\n",
    "    IS.draw_image()\n",
    "    IS.dominant_colors()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XCyPYPWlFYn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32M0_Y_NlFYo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGlXHoGrlFYq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Image_Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
